{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "model_LR_RUN_dataset.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Mount you google drive account to execute in **Google Colab**"
   ],
   "metadata": {
    "id": "U2N3LgMlysEu"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W99oxczw4dsg",
    "outputId": "156b98f6-7fd9-4625-cb74-731170bb4fc7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994907793,
     "user_tz": -120,
     "elapsed": 3642,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "%cd drive/My\\ Drive/RUN_dataset/"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/RUN_dataset\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load training set dataset and test set"
   ],
   "metadata": {
    "id": "PGiyAkG9zCq8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "TitleStyle = [\"objective\", \"subjective\", \"unknown\"]\n",
    "TitleStance = [\"agree\", \"disagree\", \"unrelated\"]\n",
    "\n",
    "def load_data(file, with_features):\n",
    "    df = pd.read_json(file, 'index')\n",
    "    df = df.rename(columns={\"VALUE_ACUERDO\": \"label\", \"TITLE\": 'text_a', 'TEXT': 'text_b'})\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df['label'].values)    \n",
    "    labels = df['label']\n",
    "    text_a = df['text_a']\n",
    "    df['text_b'] = df['text_b'].replace(r'<PARAGRAPH>', '', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace('<TEXT>', '', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace('<BREAK>', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'\\n\\n\\n\\n', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'\\n\\n', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'\\n', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'    ', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'   ', ' ', regex=True)\n",
    "    df['text_b'] = df['text_b'].replace(r'  ', ' ', regex=True)\n",
    "\n",
    "    text_b = df['text_b']\n",
    "\n",
    "    reduce = [ \"TitleStyleObjective\",\n",
    "                \"TitleStyleSubjective\",\n",
    "                \"TitleStyleUnknown\",\n",
    "                \"TitleTitle-StanceAgree\",\n",
    "                \"TitleTitle-StanceDisagree\",\n",
    "                \"TitleTitle-StanceUnrelated\"]\n",
    "    features = [\"Title\",\n",
    "                \"Subtitle\",\n",
    "                \"Lead\",\n",
    "                \"Body\",\n",
    "                \"Conclusion\",\n",
    "                \"What\",\n",
    "                \"WhatReliabilityReliable\",\n",
    "                \"WhatReliabilityUnreliable\",\n",
    "                \"WhatLack-Of-InformationYes\",               \n",
    "                \"WhatMain-Event\",\n",
    "                \"Who\",\n",
    "                \"WhoReliabilityReliable\",\n",
    "                \"WhoReliabilityUnreliable\",\n",
    "                \"WhoLack-Of-InformationYes\",                \n",
    "                \"When\",\n",
    "                \"WhenReliabilityReliable\",\n",
    "                \"WhenReliabilityUnreliable\",\n",
    "                \"WhenLack-Of-InformationYes\",                \n",
    "                \"Where\",\n",
    "                \"WhereReliabilityReliable\",\n",
    "                \"WhereReliabilityUnreliable\",\n",
    "                \"WhereLack-Of-InformationYes\",                \n",
    "                \"Why\",\n",
    "                \"WhyReliabilityReliable\",\n",
    "                \"WhyReliabilityUnreliable\",\n",
    "                \"WhyLack-Of-InformationYes\",                \n",
    "                \"How\",\n",
    "                \"HowReliabilityReliable\",\n",
    "                \"HowReliabilityUnreliable\",\n",
    "                \"HowLack-Of-InformationYes\",                \n",
    "                \"Quote\",\n",
    "                \"QuoteAuthor-StanceAgree\",\n",
    "                \"QuoteAuthor-StanceDisagree\",\n",
    "                \"QuoteAuthor-StanceUnknown\",\n",
    "                \"WhoRoleSubject\",\n",
    "                \"WhoRoleTarget\",\n",
    "                \"WhoRoleBoth\",\n",
    "                \"Key-Expression\",\n",
    "                \"Orthotypography\",\n",
    "                \"Figure\",\n",
    "                ]\n",
    "\n",
    "    df = pd.json_normalize(df['DATA'])\n",
    "    df_1 = df[reduce]\n",
    "    conditions_stance = [\n",
    "        (df_1['TitleTitle-StanceAgree'] == 1),\n",
    "        (df_1['TitleTitle-StanceDisagree'] == 1),\n",
    "        (df_1['TitleTitle-StanceUnrelated'] == 1)\n",
    "    ]\n",
    "    conditions_style = [\n",
    "        (df_1['TitleStyleObjective'] == 1),\n",
    "        (df_1['TitleStyleSubjective'] == 1),\n",
    "        (df_1['TitleStyleUnknown'] == 1)\n",
    "    ]\n",
    "\n",
    "    # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "    df_1['stance'] = np.select(conditions_stance, TitleStance)\n",
    "    df_1['style'] = np.select(conditions_style, TitleStyle)\n",
    "    df_1 = df_1.drop(columns=reduce, axis=1)\n",
    "\n",
    "    # encode columns stance and style\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(df_1['stance'].values)\n",
    "    df_1['stance'] = integer_encoded\n",
    "    integer_encoded = label_encoder.fit_transform(df_1['style'].values)\n",
    "    df_1['style'] = integer_encoded\n",
    "\n",
    "    \n",
    "    #other features\n",
    "    df_2 = df[features]\n",
    "    df_2.head()\n",
    "    \n",
    "    if with_features: \n",
    "      df = pd.concat([text_a, text_b, labels, df_1, df_2], axis=1)\n",
    "    else:\n",
    "      df = pd.concat([text_a, text_b, labels], axis=1)    \n",
    "    return df\n",
    "    \n",
    "# True if you use features\n",
    "df_train = load_data(\"training_set.json\", True)\n",
    "df_test = load_data(\"test_set.json\", True)\n",
    "\n",
    "\n",
    "df_train.head()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "-pHzNixVIt6h",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994912846,
     "user_tz": -120,
     "elapsed": 2281,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    },
    "outputId": "b9fbabf9-a08d-410e-b1dd-c9a1b3d0cc29"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: Starting with pandas version 2.0 all arguments of read_json except for the argument 'path_or_buf' will be keyword-only\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              text_a  \\\n",
       "0  Preocupación entre las personas vacunadas con ...   \n",
       "1  La mejor dieta del mundo: Adelgazar comiendo j...   \n",
       "2  Qué curioso lo del Reino Unido: Son los primer...   \n",
       "3  Colombia recibió este sábado nuevo lote de 280...   \n",
       "4  Cataluña citará masivamente a los mayores de 7...   \n",
       "\n",
       "                                              text_b  label  stance  style  \\\n",
       "0   Tenían que empezar a pasar cosas como estás y...      1       1      2   \n",
       "1   Esta más que apetecible dieta permite perder ...      1       1      2   \n",
       "2   Más información sospechosa sobre la vacuna. C...      1       1      2   \n",
       "3   Bogotá, 4 de abril de 2021. A través de su cu...      0       1      1   \n",
       "4   En algunas zonas ya se ha comenzado a vacunar...      0       1      1   \n",
       "\n",
       "   Title  Subtitle  Lead  Body  Conclusion  ...  Quote  \\\n",
       "0      1         0     1     1           1  ...      5   \n",
       "1      1         1     1     1           1  ...      0   \n",
       "2      1         0     1     1           1  ...      0   \n",
       "3      1         0     1     1           0  ...      2   \n",
       "4      1         1     1     1           0  ...      3   \n",
       "\n",
       "   QuoteAuthor-StanceAgree  QuoteAuthor-StanceDisagree  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   QuoteAuthor-StanceUnknown  WhoRoleSubject  WhoRoleTarget  WhoRoleBoth  \\\n",
       "0                          5               5              5            1   \n",
       "1                          0               2              3            0   \n",
       "2                          0               5              2            1   \n",
       "3                          2               9              4            2   \n",
       "4                          3               8              6            0   \n",
       "\n",
       "   Key-Expression  Orthotypography  Figure  \n",
       "0               4                0       0  \n",
       "1               1                0       3  \n",
       "2               9                0       1  \n",
       "3               0                0       5  \n",
       "4               0                0       4  \n",
       "\n",
       "[5 rows x 45 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-f5a2efec-3bab-4ef6-8d1a-a0a36bdb28bc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "      <th>stance</th>\n",
       "      <th>style</th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Body</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>...</th>\n",
       "      <th>Quote</th>\n",
       "      <th>QuoteAuthor-StanceAgree</th>\n",
       "      <th>QuoteAuthor-StanceDisagree</th>\n",
       "      <th>QuoteAuthor-StanceUnknown</th>\n",
       "      <th>WhoRoleSubject</th>\n",
       "      <th>WhoRoleTarget</th>\n",
       "      <th>WhoRoleBoth</th>\n",
       "      <th>Key-Expression</th>\n",
       "      <th>Orthotypography</th>\n",
       "      <th>Figure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Preocupación entre las personas vacunadas con ...</td>\n",
       "      <td>Tenían que empezar a pasar cosas como estás y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La mejor dieta del mundo: Adelgazar comiendo j...</td>\n",
       "      <td>Esta más que apetecible dieta permite perder ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qué curioso lo del Reino Unido: Son los primer...</td>\n",
       "      <td>Más información sospechosa sobre la vacuna. C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colombia recibió este sábado nuevo lote de 280...</td>\n",
       "      <td>Bogotá, 4 de abril de 2021. A través de su cu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cataluña citará masivamente a los mayores de 7...</td>\n",
       "      <td>En algunas zonas ya se ha comenzado a vacunar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5a2efec-3bab-4ef6-8d1a-a0a36bdb28bc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f5a2efec-3bab-4ef6-8d1a-a0a36bdb28bc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f5a2efec-3bab-4ef6-8d1a-a0a36bdb28bc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merge Title and body text in a new column "
   ],
   "metadata": {
    "id": "w9IFTISAzZq1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Train dataset\n",
    "df_train.insert(0,\"text\", list(df_train[\"text_a\"] + \" \" + df_train[\"text_b\"]))\n",
    "\n",
    "# Test dataset\n",
    "df_test.insert(0,\"text\", list(df_test[\"text_a\"] + \" \" + df_test[\"text_b\"]))\n"
   ],
   "metadata": {
    "id": "OZoan7VBNwdC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994684040,
     "user_tz": -120,
     "elapsed": 252,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess text to remove emojis, symbols & pictographs, URL, etc"
   ],
   "metadata": {
    "id": "5PRtNEepzqNr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "def de_emojify(text):\n",
    "    regrex_pattern = re.compile(pattern=\"[\"\n",
    "                                        u\"\\U0001F600-\\U0001F92F\"  # emoticons\n",
    "                                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                        u\"\\U00002702-\\U000027B0\"\n",
    "                                        u\"\\U000024C2-\\U0001F251\"\n",
    "                                        u\"\\U0001F190-\\U0001F1FF\"\n",
    "                                        u\"\\U0001F926-\\U0001FA9F\"                                        \n",
    "                                        u\"\\u2640-\\u2642\"\n",
    "                                        u\"\\u2600-\\u2B55\"\n",
    "                                        u\"\\u200d\"\n",
    "                                        u\"\\u23cf\"\n",
    "                                        u\"\\u23e9\"\n",
    "                                        u\"\\u231a\"\n",
    "                                        u\"\\ufe0f\"                                        \n",
    "                                        \"]+\", flags=re.UNICODE)\n",
    "    return regrex_pattern.sub(r'', text)\n",
    "\n",
    "def preprocess(value):\n",
    "    new_value = de_emojify(value)\n",
    "    new_value = re.sub(r'http\\S+', '', new_value)\n",
    "    return new_value\n",
    "\n",
    "# Train dataset\n",
    "df_train[\"text\"] = df_train[\"text\"].str.lower() \n",
    "df_train[\"text\"] = df_train.text.apply(preprocess)\n",
    "df_train.head()\n",
    "\n",
    "# Test dataset\n",
    "df_test[\"text\"] = df_test[\"text\"].str.lower() \n",
    "df_test[\"text\"] = df_test.text.apply(preprocess)"
   ],
   "metadata": {
    "id": "pRHv8KRTOPqc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994685622,
     "user_tz": -120,
     "elapsed": 226,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert text to TF-IDF vectors"
   ],
   "metadata": {
    "id": "XSRQ6qzEz_iz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "\n",
    "# create the transform\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=1000, use_idf=True,\n",
    "                            norm='l2', stop_words=stopwords.words(\"spanish\"), tokenizer=tokenize)\n",
    "\n",
    "# tokenize and build vocab\n",
    "tfidf.fit(df_train.text)\n",
    "\n",
    "\n",
    "vector = tfidf.transform(df_train.text).todense()\n",
    "new_cols = tfidf.get_feature_names_out()\n",
    "\n",
    "# remove the text column as the word 'text' may exist in the words and you'll get an error\n",
    "df_train = df_train.drop('text_a',axis=1)\n",
    "df_train = df_train.drop('text_b',axis=1)\n",
    "df_train = df_train.drop('text',axis=1)\n",
    "\n",
    "# join the tfidf values to the existing dataframe training set\n",
    "df_train = df_train.join(pd.DataFrame(vector, columns=new_cols))\n",
    "\n",
    "\n",
    "vector_test = tfidf.transform(df_test.text).todense()\n",
    "new_cols_test = tfidf.get_feature_names_out()\n",
    "# remove the text column as the word 'text' may exist in the words and you'll get an error\n",
    "df_test = df_test.drop('text_a',axis=1)\n",
    "df_test = df_test.drop('text_b',axis=1)\n",
    "df_test = df_test.drop('text',axis=1)\n",
    "\n",
    "\n",
    "# join the tfidf values to the existing dataframe test set\n",
    "df_test = df_test.join(pd.DataFrame(vector_test, columns=new_cols))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thEHeqxxOhv7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994701703,
     "user_tz": -120,
     "elapsed": 13485,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    },
    "outputId": "41f44190-55c6-4f52-9a9e-96ba2e2a5ba2"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  \"The parameter 'token_pattern' will not be used\"\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['alguna', 'alguno', 'ant', 'desd', 'dond', 'durant', 'ello', 'entr', 'erai', 'ere', 'est', 'estabai', 'estamo', 'estaremo', 'estaréi', 'estaríai', 'estaríamo', 'estemo', 'estuv', 'estuvierai', 'estuvies', 'estuviesei', 'estuvimo', 'estuvist', 'estuvistei', 'estuviéramo', 'estuviésemo', 'estábamo', 'estái', 'estéi', 'fuerai', 'fues', 'fuesei', 'fuimo', 'fuist', 'fuistei', 'fuéramo', 'fuésemo', 'habremo', 'habréi', 'habríai', 'habríamo', 'habéi', 'habíai', 'habíamo', 'hayamo', 'hayái', 'hemo', 'hubierai', 'hubies', 'hubiesei', 'hubimo', 'hubist', 'hubistei', 'hubiéramo', 'hubiésemo', 'má', 'nosotra', 'nosotro', 'porqu', 'seamo', 'seremo', 'seréi', 'seríai', 'seríamo', 'seái', 'sient', 'sobr', 'soi', 'somo', 'tendremo', 'tendréi', 'tendríai', 'tendríamo', 'tene', 'tenemo', 'tengamo', 'tengái', 'tenéi', 'teníai', 'teníamo', 'tien', 'tuvierai', 'tuvies', 'tuviesei', 'tuvimo', 'tuvist', 'tuvistei', 'tuviéramo', 'tuviésemo', 'vosotra', 'vosotro', 'éramo'] not in stop_words.\n",
      "  % sorted(inconsistent)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the Logistic Regression model and computing metrics"
   ],
   "metadata": {
    "id": "RRh7w6VC0FGP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score,f1_score,recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "models = [LogisticRegression(random_state=0)]\n",
    "\n",
    "# Train\n",
    "y_train = df_train.iloc[:,0]\n",
    "x_train = df_train.iloc[:,1:]\n",
    "\n",
    "# Test \n",
    "y_test = df_test.iloc[:,0]\n",
    "x_test = df_test.iloc[:,1:]\n",
    "  \n",
    "for model in models:                \n",
    "  model.fit(x_train, y_train)\n",
    "  y_pred = model.predict(x_test)\n",
    "      \n",
    "  print(model)\n",
    "  print(accuracy_score(y_test, y_pred.round()))\n",
    "  print(f1_score(y_test, y_pred.round(), average='macro'))\n",
    "  print(confusion_matrix(y_test, y_pred.round()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFmoBbVaLaES",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658994702039,
     "user_tz": -120,
     "elapsed": 374,
     "user": {
      "displayName": "Robiert Sepúlveda Torres",
      "userId": "04395768865630341141"
     }
    },
    "outputId": "5128ffc9-ee8b-45fe-bfe0-023112f34d8a"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(random_state=0)\n",
      "0.95\n",
      "0.949874686716792\n",
      "[[ 9  1]\n",
      " [ 0 10]]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ]
  }
 ]
}
